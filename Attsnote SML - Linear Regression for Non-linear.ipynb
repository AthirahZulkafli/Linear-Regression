{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10833be1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Supervised Machine Learning by @attzulkafli."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9b430",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using Linear Regression for non-linear relations\n",
    "\n",
    "Consider the following case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b85d6138-7ddb-429d-ba23-41699d4fcd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186d0ea6-30ff-497e-99b3-4c90a3f052b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "016f5d0c-8569-4a88-a533-75fc7aa7135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41bdd9f0-21b8-4123-b79f-1f0df67c3c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2910572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = (10 * (2 * np.random.rand(100) - 1))[:, np.newaxis]\n",
    "# b0 = 15, b1 = 0, b2 = -1.7, b3 = 0.2\n",
    "y = 15 - 1.7 * X**2 + 0.2 * X**3 + np.random.normal(scale=5, size=X.shape)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, y_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346137a6",
   "metadata": {},
   "source": [
    "### Basis functions\n",
    "\n",
    "A trick to adapt linear regression to nonlinear relationships between features and targets is to transform the data and generate new features from the existing ones using basis functions. A very common set of basis functions are **polynomial basis functions** $f_n(x) = x^n$, which transform a simple linear regression from\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x $$\n",
    "\n",
    "into\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\ldots + \\beta_n x^n$$\n",
    "\n",
    "We are free to choose how many polynomials to include. In fact, the basis functions $f(x)$ can be practically anything; we are free to transform features however we deem necessary.\n",
    "\n",
    "This can, of course, also be extended to multiple linear regression so that, e.g.\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 $$\n",
    "\n",
    "could become\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_{1a} x_1 + \\beta_{1b} x_1^2 + \\beta_{2a} x_2 + \\beta_{2b} x_2^2$$\n",
    " \n",
    "Note that this is still a linear model. Linearity in the context of modelling means that the coefficients $\\beta_i$ are only ever added to (or subtracted from) each other. The basis functions $f(x)$ may very well be non-linear, though. For example,\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2 $$\n",
    "\n",
    "is a linear model, despite the $x_1 x_2$ term, whereas\n",
    "\n",
    "$$ y = \\beta_0 + \\frac{\\beta_1 x}{\\beta_2 + x}$$\n",
    "\n",
    "is a non-linear model, despite only having one feature, because the coefficients are divided by each other.\n",
    "\n",
    "**All we are doing is engineering new features to capture nonlinear patterns!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138bdb2c",
   "metadata": {},
   "source": [
    "### Regression with polynomial basis functions\n",
    "\n",
    "The polynomial basis functions are so common and useful that this transformation is built into Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e10ea88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1d = np.array([2, 3, 4])[:, np.newaxis]\n",
    "x_1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "568e8f5a-39e9-4345-8f49-eecd8dcd2bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38222667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,   4.,   8.,  16.],\n",
       "       [  3.,   9.,  27.,  81.],\n",
       "       [  4.,  16.,  64., 256.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly.fit(x_1d)\n",
    "x_poly = poly.transform(x_1d)\n",
    "x_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a3aa785-18f3-4860-8db6-ef8f2cb9fef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   4.,   8.,  16.],\n",
       "       [  1.,   3.,   9.,  27.,  81.],\n",
       "       [  1.,   4.,  16.,  64., 256.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=True)\n",
    "poly.fit(x_1d)\n",
    "x_poly = poly.transform(x_1d)\n",
    "x_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee4ea265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7096bb62-64c8-41bb-9928-56d3076962a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b38dec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('polynomialfeatures',\n",
       "                 PolynomialFeatures(degree=3, include_bias=False)),\n",
       "                ('minmaxscaler', MinMaxScaler()),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_pipeline = make_pipeline(PolynomialFeatures(degree=3, include_bias=False),MinMaxScaler(),LinearRegression())\n",
    "poly_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b4e43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('polynomialfeatures', PolynomialFeatures(degree=3, include_bias=False)),\n",
       " ('minmaxscaler', MinMaxScaler()),\n",
       " ('linearregression', LinearRegression())]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_pipeline.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c6dd44-cb27-46b7-9b28-d9a9d84b39ed",
   "metadata": {},
   "source": [
    "We can use the pipeline as a single object to fit the non-linear relationship from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "654c107c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "poly_pipeline.fit(X, y)\n",
    "X_pred = np.linspace(X.min(), X.max(), 100)[:, np.newaxis]\n",
    "y_pred = poly_pipeline.predict(X_pred)\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X_pred, y_pred, c='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34718526",
   "metadata": {},
   "source": [
    "### A comment on `PolynomialFeatures`\n",
    "The `PolynomialFeatures` preprocessor doesn't just apply exponents to features but also looks at interaction terms $x_i^n x_j^m$. For example, applying `PolynomialFeatures(degree=2)` to the following linear model:\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 $$\n",
    "\n",
    "will result in:\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1^2 + \\beta_4 x_2^2 + \\beta_5 x_1 x_2$$\n",
    "\n",
    "`PolynomialFeatures` will generate all interaction terms where the sum of the exponents is less than or equal to `degree`. So applying `PolynomialFeatures(degree=3)` to the linear model above results in:\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "y = \\beta_0 &+ \\beta_1 x_1 + \\beta_2 x_2\\\\\n",
    "            &+ \\beta_3 x_1^2 + \\beta_4 x_2^2\\\\\n",
    "            &+ \\beta_5 x_1 x_2\\\\\n",
    "            &+ \\beta_6 x_1^3 + \\beta_7 x_2^3\\\\\n",
    "            &+ \\beta_7 x_1^2 x_2 + \\beta_8 x_2^2 x_1\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Keep this in mind when generating polynomial expansions: the number of resulting features can become computationally problematic if `degree` is too large. For example, if we start with 10 features, a polynomial expansion with `degree=4` will result in 1000 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c0561dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, -5, -3, -2,  2,  3,  0, -3,  1, -4],\n",
       "       [-5,  4, -5, -4, -5, -2,  1, -2, -1,  0],\n",
       "       [ 1,  2, -4,  1, -3,  1, -1, -1, -4, -1],\n",
       "       [ 3,  4,  4,  0, -5, -3, -1,  2,  1, -3],\n",
       "       [-2,  1, -2,  2, -1,  2,  1,  4,  2, -2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1d = np.random.randint(low=-5, high=5, size=(5, 10))\n",
    "x_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ae1d880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "765288e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1001)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_poly = PolynomialFeatures(degree=4).fit_transform(x_1d)\n",
    "x_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1a1bcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:    (5, 10)\n",
      "Transformed shape: (5, 1001)\n",
      "Interaction Only Transformed shape: (5, 386)\n"
     ]
    }
   ],
   "source": [
    "x_1d = np.random.randint(low=-5, high=5, size=(5, 10))\n",
    "x_poly = PolynomialFeatures(degree=4).fit_transform(x_1d)\n",
    "print(\"Original shape:    {}\".format(x_1d.shape))\n",
    "print(\"Transformed shape: {}\".format(x_poly.shape))\n",
    "\n",
    "# set interaction_only = True only creates x_i * x_j for i != j\n",
    "x_poly_inter = PolynomialFeatures(degree=4, interaction_only = True).fit_transform(x_1d)\n",
    "print(\"Interaction Only Transformed shape: {}\".format(x_poly_inter.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6776b5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Best Practice for Machine Learning\n",
    "In the previous examples and exercises, we have assessed the performance of the trained model on the data it was trained on. This is problematic, as we have no guarantee that the model will capture the true relationship between the features and target values. Consider the following example:\n",
    "\n",
    "<center><img src=\"../images/overfitting.png\" /></center>\n",
    "\n",
    "The black dots represent the raw input data and the two lines represent two models trained on this data.\n",
    "\n",
    "- The blue line perfectly predicts the target value for each data point. This model has a perfect performance, i.e. $R^2 = 1$, when assessed on the training data. However, it clearly does not capture the true relationship between the feature and the target value.\n",
    "- The black line, although not a perfect fit, i.e. $R^2 < 1$, much more accurately describes the true relationship between feature and target.\n",
    "\n",
    "To avoid this phenomenon, called **overfitting**, we can split our data into a training and a test data set. This allows us to train the model on one part of the data and then assess its performance on data it has never seen to determine how well it generalizes to new data.\n",
    "\n",
    "We can use the `sklearn.model_selection.train_test_split` function to divide the data into 2 sets for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd87553d-e031-482a-aefa-8227e2fcc4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate random data\n",
    "rng = np.random.RandomState(42)\n",
    "X = 10 * rng.rand(100, 3)\n",
    "y = 0.5 + np.dot(X, [1.5, -2., 1.]) + np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48ae00cc-d0f5-4dda-83f6-0ca228fac6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (100, 3)\n",
      "y.shape (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X.shape\", X.shape)\n",
    "print(\"y.shape\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "927f5761-2e82-4d5c-b0fd-07c703e8c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4aa41394-20cf-44e1-9cf8-ad985d8cdca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (75, 3)\n",
      "y_train.shape (75,)\n",
      "X_test.shape (25, 3)\n",
      "y_test.shape (25,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"y_test.shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3917e072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.16434636606049358\n",
      "Slope:     [ 1.50907329 -1.99217103  1.06626408]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression().fit(X_train, y_train)\n",
    "print(\"Intercept: {}\".format(model.intercept_))\n",
    "print(\"Slope:     {}\".format(model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b6f74944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2 Score: 0.9856224019215895\n",
      "Test R2 Score:  0.9738315278503855\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "print(\"Train R2 Score: {}\".format(r2_train))\n",
    "print(\"Test R2 Score:  {}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a4ea5",
   "metadata": {},
   "source": [
    "### train-test split in one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e7b9c117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (100, 3)\n",
      "y.shape (100,)\n",
      "X_train.shape (75, 3)\n",
      "y_train.shape (75,)\n",
      "X_test.shape (25, 3)\n",
      "y_test.shape (25,)\n",
      "Intercept: 0.7910543974829567\n",
      "Slope:     [ 1.47925651 -1.99290372  0.92413227]\n",
      "Train R2 Score: 0.9878030324500066\n",
      "Test R2 Score:  0.9707588434928615\n"
     ]
    }
   ],
   "source": [
    "# Generate random data\n",
    "rng = np.random.RandomState(42)\n",
    "X = 10 * rng.rand(100, 3)\n",
    "y = 0.5 + np.dot(X, [1.5, -2., 1.]) + np.random.randn(100)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Intercept: {}\".format(model.intercept_))\n",
    "print(\"Slope:     {}\".format(model.coef_))\n",
    "print(\"Train R2 Score: {}\".format(r2_train))\n",
    "print(\"Test R2 Score:  {}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada9512",
   "metadata": {},
   "source": [
    "### Exercise - Train and test the advertising dataset\n",
    "\n",
    "Train a multiple linear regression on the advertising dataset as above, but this time reserve a fraction of the data as a test set to assess the performance. Do this with the following splits:\n",
    "- Training: 50%, Test: 50%\n",
    "- Training 95%, Test: 5%\n",
    "- Training 5%, Test: 95%\n",
    "\n",
    "Hint: The `test_size` argument of `train_test_split` takes a number between 0 and 1 indicating the relative size of the test set, e.g. 0.3 corresponds to \"Reserve 30% of the data as a test set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b305b5-0dee-41f7-ac20-f3fa9984d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a0b539db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sales[[\"TV\", \"radio\", \"newspaper\"]]\n",
    "y = sales[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55c7d35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Size 50% ===\n",
      "   R2 Train: 0.984\n",
      "   R2 Test:  0.984\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "#Training: 50%, Test: 50%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=101)\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "r2_train = r2_score(y_train, model.predict(X_train))\n",
    "r2_test = r2_score(y_test, model.predict(X_test))\n",
    "\n",
    "print(\"=== Test Size 50% ===\")\n",
    "print(\"   R2 Train: {:.3f}\".format(r2_train))\n",
    "print(\"   R2 Test:  {:.3f}\".format(r2_test))\n",
    "print(\"=====================\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36af87ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Size 50% ===\n",
      "   R2 Train: 0.984\n",
      "   R2 Test:  0.970\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "#Training 95%, Test: 5%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=101)\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "r2_train = r2_score(y_train, model.predict(X_train))\n",
    "r2_test = r2_score(y_test, model.predict(X_test))\n",
    "\n",
    "print(\"=== Test Size 50% ===\")\n",
    "print(\"   R2 Train: {:.3f}\".format(r2_train))\n",
    "print(\"   R2 Test:  {:.3f}\".format(r2_test))\n",
    "print(\"=====================\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77b0f938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Size 50% ===\n",
      "   R2 Train: 0.997\n",
      "   R2 Test:  0.837\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "#Training 5%, Test: 95%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.95, random_state=101)\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "r2_train = r2_score(y_train, model.predict(X_train))\n",
    "r2_test = r2_score(y_test, model.predict(X_test))\n",
    "\n",
    "print(\"=== Test Size 50% ===\")\n",
    "print(\"   R2 Train: {:.3f}\".format(r2_train))\n",
    "print(\"   R2 Test:  {:.3f}\".format(r2_test))\n",
    "print(\"=====================\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f209d50",
   "metadata": {},
   "source": [
    "## Explore sklearns datasets\n",
    "\n",
    "Sklearn provides both toy as well as real-world datasets: https://scikit-learn.org/stable/datasets/index.html.\n",
    "\n",
    "We can load these with the built-in `sklearn.datasets.load_*()` or `sklearn.datasets.fetch_*()` functions. Python will download these datasets if they are not already saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "227b0136-24c3-4eeb-b0cd-51997b22b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bb53123",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = sklearn.datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aaac50b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "814d8028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a6745",
   "metadata": {},
   "source": [
    "**Exercise - Boston Housing Data**\n",
    "\n",
    "We're going to predict housing prices\n",
    "\n",
    "1. Load the sklearn dataset of the Boston house prices. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64229d66-a66c-4a17-ab4f-ea0752fe884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1bb96de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change scikit learn dataset o pd dataframe\n",
    "#alternative\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "boston_data = datasets.load_boston()\n",
    "boston = pd.DataFrame(boston_data.data, columns=boston_data.feature_names)\n",
    "boston['target'] = pd.Series(boston_data.target)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2541014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in Boston dataset: dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n",
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boston = sklearn.datasets.load_boston()\n",
    "print(\"Keys in Boston dataset: {}\".format(boston.keys()))\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df78d703-4976-4a20-bb3a-1b298cf82759",
   "metadata": {},
   "source": [
    "2. Use a multiple linear regression to predict housing prices\n",
    "    - Divide the data into a training and test data set (70% training/30% test split)\n",
    "    - Train a multiple linear regression model\n",
    "    - Assess the performance of the model using the $R^2$ score\n",
    "    - Play around with the train/test split size to see how the fit changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fd9a3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=boston.data\n",
    "Y=boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6c1d397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7edfb275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56817376-59c8-45fe-bf64-83e869416c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "294419f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2 Score: 0.7434997532004697\n",
      "Test R2 Score:  0.711226005748496\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "print(\"Train R2 Score: {}\".format(r2_score(Y_train, Y_train_pred)))\n",
    "print(\"Test R2 Score:  {}\".format(r2_score(Y_test, Y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "46a495d1-e862-46c7-85bd-e8beeab2fc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train score: 0.7434997532004697\n",
      "R2 test score: 0.711226005748496\n"
     ]
    }
   ],
   "source": [
    "#alternative\n",
    "model = LinearRegression().fit(X_train, Y_train)\n",
    "print(\"R2 train score: {}\".format(model.score(X_train, Y_train)))\n",
    "print(\"R2 test score: {}\".format(model.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "53c43806-2dfe-41c7-98cc-47880ca3edb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train score: 0.7671674226821155\n",
      "R2 test score: 0.7412232713454907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3237: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler=PowerTransformer().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "LR_boston_scaled = LinearRegression().fit(X_train_scaled, Y_train)\n",
    "print(\"R2 train score: {}\".format(LR_boston_scaled.score(X_train_scaled, Y_train)))\n",
    "print(\"R2 test score: {}\".format(LR_boston_scaled.score(X_test_scaled, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ddd91-025f-4749-b093-d9a4983c8036",
   "metadata": {},
   "source": [
    "3. Try to improve the regression by using polynomial features\n",
    "    - Create an sklearn pipeline that generates polynomial features and then trains a multiple linear regression on these features\n",
    "    - Assess the performance ($R^2$ score) of this polynomial regression on the training and test data\n",
    "    - Do this for polynomial degrees 2, 3, and 4.\n",
    "    - Compare your results with the multiple linear regression above. What are your observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a904b1bf-a06c-4ed1-848d-7743b1b52583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b40ae2a8-bea6-4c47-8ef6-4ef44627e1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train score (degree=2): 0.9469794920108197\n",
      "R2 test score (degree=2): 0.6610321968877222\n"
     ]
    }
   ],
   "source": [
    "poly_pipeline = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False), \n",
    "    MinMaxScaler(), \n",
    "    LinearRegression())\n",
    "poly_pipeline.fit(X_train, Y_train)\n",
    "\n",
    "print(\"R2 train score (degree=2): {}\".format(poly_pipeline.score(X_train, Y_train)))\n",
    "print(\"R2 test score (degree=2): {}\".format(poly_pipeline.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0a6f6bed-dc9b-4d52-b998-adf675100b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train score (degree=3): 1.0\n",
      "R2 test score (degree=3): -27.24238218792941\n"
     ]
    }
   ],
   "source": [
    "poly_pipeline = make_pipeline(\n",
    "    PolynomialFeatures(degree=3, include_bias=False), \n",
    "    MinMaxScaler(), \n",
    "    LinearRegression())\n",
    "poly_pipeline.fit(X_train, Y_train)\n",
    "\n",
    "print(\"R2 train score (degree=3): {}\".format(poly_pipeline.score(X_train, Y_train)))\n",
    "print(\"R2 test score (degree=3): {}\".format(poly_pipeline.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1f7a10aa-f109-4d8a-b9df-a6832d5685df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train score (degree=4): 1.0\n",
      "R2 test score (degree=4): -5.217699556005522\n"
     ]
    }
   ],
   "source": [
    "poly_pipeline = make_pipeline(\n",
    "    PolynomialFeatures(degree=4, include_bias=False), \n",
    "    MinMaxScaler(), \n",
    "    LinearRegression())\n",
    "poly_pipeline.fit(X_train, Y_train)\n",
    "\n",
    "print(\"R2 train score (degree=4): {}\".format(poly_pipeline.score(X_train, Y_train)))\n",
    "print(\"R2 test score (degree=4): {}\".format(poly_pipeline.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "79f3665f-b339-4823-9f28-6d347b8c3c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train score: 0.7671674226821155\n",
      "R2 test score: 0.7412232713454907\n",
      "R2 train score (degree=2): 0.9469794920108197\n",
      "R2 test score (degree=2): 0.6610321968877222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3237: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "# improve the regression by using polynomial features\n",
    "#in one cell\n",
    "\n",
    "X=boston.data\n",
    "Y=boston.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LinearRegression().fit(X_train,Y_train)\n",
    "\n",
    "## optional\n",
    "scaler=PowerTransformer().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "##\n",
    "\n",
    "LR_boston_scaled = LinearRegression().fit(X_train_scaled, Y_train)\n",
    "print(\"R2 train score: {}\".format(LR_boston_scaled.score(X_train_scaled, Y_train)))\n",
    "print(\"R2 test score: {}\".format(LR_boston_scaled.score(X_test_scaled, Y_test)))\n",
    "\n",
    "poly_pipeline = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False), \n",
    "    MinMaxScaler(), \n",
    "    LinearRegression())\n",
    "poly_pipeline.fit(X_train, Y_train)\n",
    "\n",
    "print(\"R2 train score (degree=2): {}\".format(poly_pipeline.score(X_train, Y_train)))\n",
    "print(\"R2 test score (degree=2): {}\".format(poly_pipeline.score(X_test, Y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9373899-f790-4f13-9aa5-5065a9bd7771",
   "metadata": {},
   "source": [
    "# Lasso, Ridge, and Elastic Net Regression: Regularization\n",
    "\n",
    "Ridge and Lasso regression are powerful techniques generally used for creating parsimonious models in presence of a large number of features. Here large can typically mean either of two things:\n",
    "\n",
    "- Large enough to enhance the tendency of a model to overfit (as low as 10 variables might cause overfitting)\n",
    "- Large enough to cause computational challenges. With modern systems, this situation might arise in case of millions or billions of features\n",
    "\n",
    "Generally, they work by penalizing the magnitude of coefficients of features along with minimizing the error between predicted and actual observations. These are called regularization techniques. Regularization reduces the model complexity and prevents over-fitting. The key difference is in how they assign penalty to the coefficients:\n",
    "\n",
    "**Regression:**\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1  x_1 + \\beta_2  x_2 + ... + \\beta_n  x_n $$\n",
    "\n",
    "- Minimize Error: $$\\sum_{i=1}^{m} {(y - \\hat{y})^2} = \\sum_{i=1}^{m} {(y -  \\beta_0 + \\beta_1  x_1 + \\beta_2  x_2 + ... + \\beta_n  x_n )^2}$$\n",
    "\n",
    "**Lasso Regression:**\n",
    "\n",
    "**LASSO** stands for ``Least Absolute Shrinkage and Selection Operator`` where emphasis on the 2 key words  absolute and selection.\n",
    "\n",
    "Lasso regression performs **L1 regularization**, i.e. it adds a factor of sum of absolute value of coefficients in the optimization objective. \n",
    "\n",
    "- Minimize Error: $$\\sum_{i=1}^{m} {(y - \\hat{y})^2} + \\alpha\\sum_{i=1}^{n} {|\\beta_i|} = \\sum_{i=1}^{m} {(y -  \\beta_0 - \\beta_1  x_1 - \\beta_2  x_2 - ... - \\beta_n  x_n )^2} + \\alpha\\sum_{i=1}^{n} {|\\beta_i|}$$\n",
    "\n",
    "Thus, lasso regression optimizes the following:\n",
    "\n",
    "**Objective = RSS +  * (sum of absolute value of coefficients)**\n",
    "\n",
    "Here,  (alpha) works similar to that of ridge and provides a trade-off between balancing RSS and magnitude of coefficients. Like that of ridge,  can take various values. Lets iterate it here briefly:\n",
    "\n",
    "1.  = 0: Same coefficients as simple linear regression\n",
    "2.  = : All coefficients zero (same logic as before)\n",
    "3. 0 <  < : coefficients between 0 and that of simple linear regression\n",
    "\n",
    "**Ridge Regression:**\n",
    "\n",
    "\n",
    "As mentioned before, ``ridge regression`` performs L2 regularization, i.e. it adds a factor of sum of squares of coefficients in the optimization objective.\n",
    "\n",
    "- Minimize Error: $$\\sum_{i=1}^{m} {(y - \\hat{y})^2}+ \\alpha \\sum_{i=1}^{n} {\\beta_i^2} = \\sum_{i=1}^{m} {(y -  \\beta_0 - \\beta_1  x_1 - \\beta_2  x_2 - ... - \\beta_n  x_n )^2} + \\alpha \\sum_{i=1}^{n} {\\beta_i^2}$$\n",
    "\n",
    "Thus, ridge regression optimizes the following:\n",
    "\n",
    "**Objective = RSS +  * (sum of square of coefficients)**\n",
    "\n",
    "Here,  (alpha) is the parameter which balances the amount of emphasis given to minimizing RSS vs minimizing sum of square of coefficients.  can take various values:\n",
    "\n",
    "1.  = 0:\n",
    "    - The objective becomes same as simple linear regression.\n",
    "    - Well get the same coefficients as simple linear regression.\n",
    "2.  = :\n",
    "    - The coefficients will be zero. Why? Because of infinite weightage on square of coefficients, anything less than zero will make the objective infinite.\n",
    "3. 0 <  < :\n",
    "    - The magnitude of  will decide the weightage given to different parts of objective.\n",
    "    - The coefficients will be somewhere between 0 and ones for simple linear regression.\n",
    "\n",
    "**Elastic Net Regression:**\n",
    "\n",
    "- Minimize Error: $$\\sum_{i=1}^{m} {(y - \\hat{y})^2}+ \\lambda_1 \\sum_{i=1}^{n} {|\\beta_i|} + \\lambda_2 \\sum_{i=1}^{n} {\\beta_i^2} = \\sum_{i=1}^{m} {(y -  \\beta_0 - \\beta_1  x_1 - \\beta_2  x_2 - ... - \\beta_n  x_n )^2} + \\lambda_1 \\sum_{i=1}^{n} {|\\beta_i|} + \\lambda_2 \\sum_{i=1}^{n} {\\beta_i^2}$$\n",
    "\n",
    "In `sklearn`, the relationship between $\\lambda_1$ and $\\lambda_2$ is defined by two parameters in `ElasticNet` function `alpha` and `l1_ratio` where:\n",
    "$$\\alpha = \\lambda_1 + \\lambda_2$$\n",
    "and $$ l1-ratio = \\frac {\\lambda_1}{(\\lambda_1 + \\lambda_2)}$$\n",
    "\n",
    "For example, if $\\alpha = 1$, and l1_ratio = 0.3, then:\n",
    "$$ {\\lambda_1 + \\lambda_2 = 1} \\\\ { \\frac {\\lambda_1}{(\\lambda_1 + \\lambda_2)} = 0.3}$$\n",
    "Therefore: \n",
    "$$ {\\lambda_1 = 0.3} \\\\  {\\lambda_2 = 0.7}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
